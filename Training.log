2024-04-15 19:04:06,902 - agents.Base_Agent - INFO - 0 -- FrameStack<ClipRewardEnv<ScaledFloatFrame<WarpFrame<FireResetEnv<EpisodicLifeEnv<TimeLimit<MaxAndSkipEnv<NoopResetEnv<OrderEnforcing<PassiveEnvChecker<Atari
2024-04-15 19:04:06,903 - agents.Base_Agent - INFO - 1 -- DISCRETE
2024-04-15 19:04:06,903 - agents.Base_Agent - INFO - 2 -- 6
2024-04-15 19:04:06,904 - agents.Base_Agent - INFO - 3 -- None
2024-04-15 19:04:06,904 - agents.Base_Agent - INFO - 4 -- (4, 84, 84)
2024-04-15 19:04:06,905 - agents.Base_Agent - INFO - 5 -- {'Actor': {'learning_rate': 0.0003, 'linear_hidden_units': [['conv', 32, 3, 1, 0], ['maxpool', 2, 2, 0], ['conv', 64, 3, 1, 2], ['avgpool', 2, 2, 0], ['linear', 10]], 'final_layer_activation': 'Softmax', 'batch_norm': False, 'tau': 0.005, 'gradient_clipping_norm': 5, 'initialiser': 'Xavier'}, 'Critic': {'learning_rate': 0.0003, 'linear_hidden_units': [['conv', 32, 3, 1, 0], ['maxpool', 2, 2, 0], ['conv', 64, 3, 1, 2], ['avgpool', 2, 2, 0], ['linear', 10]], 'final_layer_activation': None, 'batch_norm': False, 'buffer_size': 1000000, 'tau': 0.005, 'gradient_clipping_norm': 5, 'initialiser': 'Xavier'}, 'min_steps_before_learning': 10000, 'batch_size': 256, 'discount_rate': 0.99, 'mu': 0.0, 'theta': 0.15, 'sigma': 0.25, 'action_noise_std': 0.2, 'action_noise_clipping_range': 0.5, 'update_every_n_steps': 1, 'learning_updates_per_learning_session': 1, 'automatically_tune_entropy_hyperparameter': True, 'entropy_term_weight': None, 'add_extra_noise': False, 'do_evaluation_iterations': True, 'clip_rewards': True}
2024-04-15 19:04:06,906 - agents.Base_Agent - INFO - 6 -- inf
2024-04-15 19:04:06,907 - agents.Base_Agent - INFO - 7 -- 100
2024-04-15 19:04:06,907 - agents.Base_Agent - INFO - 8 -- cuda:0
